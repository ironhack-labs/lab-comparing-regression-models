{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4204158",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Lab | Comparing regression models\n",
    "\n",
    "\n",
    "For this lab, we will be using the same dataset we used in the previous labs. We recommend using the same notebook since you will be reusing the same variables you previous created and used in labs. \n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. In this final lab, we will model our data. Import sklearn `train_test_split` and separate the data.\n",
    "2. Try a simple linear regression with all the data to see whether we are getting good results.\n",
    "3. Great! Now define a function that takes a list of models and train (and tests) them so we can try a lot of them without repeating code.\n",
    "4. Use the function to check `LinearRegressor` and `KNeighborsRegressor`.\n",
    "5. You can check also the `MLPRegressor` for this task!\n",
    "6. Check and discuss the results.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasting below code from previous labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3617043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "\n",
    "# These are the normal libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# This is just so that we don't get annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# This is the most common viz library in python\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# This one is the above on steroids\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# These Libs are for stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d5b32c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Two-Door Car', 'Four-Door Car', 'SUV', 'Luxury SUV', 'Sports Car',\n",
       "       'Luxury Car'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\filip\\OneDrive\\Desktop\\IRONHACK\\Labs\\Week5\\lab-cleaning-categorical-data\\files_for_lab\\we_fn_use_c_marketing_customer_value_analysis.csv\")\n",
    "\n",
    "cols = []\n",
    "for i in range(len(df.columns)):\n",
    "    cols.append(df.columns[i].lower().replace(' ','_'))\n",
    "df.columns = cols\n",
    "\n",
    "df.dtypes # Checking data types\n",
    "\n",
    "categorical_df = df.select_dtypes(include=['object']) #Saving categorical columns into df\n",
    "\n",
    "categorical_df.isna().sum() #Checking for null values/No null values\n",
    "\n",
    "# Checking unique values in each column\n",
    "categorical_df['customer'].unique() #Categorical\n",
    "categorical_df['state'].unique() #Categorical\n",
    "categorical_df['response'].unique() #Categorical\n",
    "categorical_df['coverage'].unique() #Categorical\n",
    "categorical_df['education'].unique() #Categorical\n",
    "categorical_df['effective_to_date'].unique() #Date Time\n",
    "categorical_df['employmentstatus'].unique() #Categorical\n",
    "categorical_df['gender'].unique() #Categorical\n",
    "categorical_df['location_code'].unique() #Categorical\n",
    "categorical_df['marital_status'].unique() #Categorical\n",
    "categorical_df['policy_type'].unique() #Categorical\n",
    "categorical_df['policy'].unique() #Categorical\n",
    "categorical_df['renew_offer_type'].unique() #Categorical\n",
    "categorical_df['sales_channel'].unique() #Categorical\n",
    "categorical_df['vehicle_class'].unique() #Categorical\n",
    "categorical_df['vehicle_size'].unique() #Categorical\n",
    "\n",
    "# will drop effective_to_date and later if needed will convert to datetime on the original df\n",
    "\n",
    "categorical_df = categorical_df.drop(['effective_to_date'], axis = 1)\n",
    "\n",
    "# will also drop customer because it doesn't really give us any information\n",
    "\n",
    "categorical_df = categorical_df.drop(['customer'], axis = 1)\n",
    "\n",
    "categorical_df['policy_type'].unique() #Categorical\n",
    "\n",
    "'''policy_type has the following unique values:['Corporate Auto', 'Personal Auto', 'Special Auto']\n",
    "\n",
    "   policy has the following unique values:['Corporate L3', 'Personal L3', 'Corporate L2', 'Personal L1',\n",
    "    'Special L2', 'Corporate L1', 'Personal L2', 'Special L1','Special L3']\n",
    "    \n",
    "It appears that the values in policy are the same as in policy_type but broken down into subtypes, more detailed information.\n",
    "\n",
    "I would drop policy if in need to drop one of the two''' \n",
    "\n",
    "# Variables I would chose to hot encode\n",
    "categorical_df['response'].unique()\n",
    "categorical_df['coverage'].unique()\n",
    "categorical_df['gender'].unique()\n",
    "categorical_df['location_code'].unique()\n",
    "categorical_df['marital_status'].unique()\n",
    "categorical_df['policy_type'].unique()\n",
    "categorical_df['vehicle_size'].unique()\n",
    "\n",
    "# In my opinion these columns have too many values to hot encode, will drop for now\n",
    "categorical_df['state'].unique()\n",
    "categorical_df['education'].unique()\n",
    "categorical_df['employmentstatus'].unique()\n",
    "categorical_df['policy'].unique()\n",
    "categorical_df['renew_offer_type'].unique()\n",
    "categorical_df['sales_channel'].unique()\n",
    "categorical_df['vehicle_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1f2e2419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous columns:\n",
      "['customer_lifetime_value', 'income', 'total_claim_amount']\n",
      "\n",
      "Discrete columns:\n",
      "['effective_to_date', 'monthly_premium_auto', 'months_since_last_claim', 'months_since_policy_inception', 'number_of_open_complaints', 'number_of_policies']\n"
     ]
    }
   ],
   "source": [
    "customer_df = pd.read_csv(r\"C:\\Users\\filip\\OneDrive\\Desktop\\IRONHACK\\Labs\\Week5\\lab-cleaning-numerical-data\\files_for_lab\\we_fn_use_c_marketing_customer_value_analysis.csv\")\n",
    "customer_df.head()\n",
    "customer_df.shape\n",
    "customer_df.dtypes\n",
    "\n",
    "# Renaming columns\n",
    "cols = []\n",
    "for i in range(len(customer_df.columns)): \n",
    "    cols.append(customer_df.columns[i].lower().replace(' ', '_')) \n",
    "customer_df.columns = cols\n",
    "\n",
    "# Changing effective to date column to datetime format\n",
    "\n",
    "customer_df['effective_to_date'] = pd.to_datetime(customer_df['effective_to_date'])\n",
    "\n",
    "# Creating numerical data frame\n",
    "\n",
    "numerical_df = customer_df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Creating a function to differentiate betweens continuous and discrete variables\n",
    "\n",
    "def decision(data, threshold=250):\n",
    "    continuous_cols = []\n",
    "    discrete_cols = []\n",
    "    for column in data.columns:\n",
    "        unique_count = data[column].nunique()\n",
    "        if unique_count <= threshold:\n",
    "            discrete_cols.append(column)\n",
    "        else:\n",
    "            continuous_cols.append(column)\n",
    "    return continuous_cols, discrete_cols\n",
    "\n",
    "\n",
    "continuous_columns, discrete_columns = decision(numerical_df)\n",
    "print(\"Continuous columns:\")\n",
    "print(continuous_columns)\n",
    "print(\"\\nDiscrete columns:\")\n",
    "print(discrete_columns)\n",
    "    \n",
    "continuous_df = numerical_df[continuous_columns]\n",
    "discrete_df = numerical_df[discrete_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "49d52a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concating both dfs\n",
    "\n",
    "df = pd.concat([numerical_df, categorical_df], axis = 1)\n",
    "\n",
    "# Dropping outliers\n",
    "\n",
    "def outliers_drop(data, columns, threshold=1.5):\n",
    "    df_c = df.copy()\n",
    "    for column in columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "        df_c = df_c[(df_c[column] >= lower_bound) & (df_c[column] <= upper_bound)]\n",
    "\n",
    "    return df_c\n",
    "\n",
    "\n",
    "clean_df = outliers_drop(df, ['total_claim_amount', 'income'], threshold=1.5).reset_index(drop = True)\n",
    "\n",
    "# Copying df \n",
    "\n",
    "df_clean = clean_df.copy()\n",
    "\n",
    "# Normalize continuous variables\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_continuous = scaler.fit_transform(continuous_df)\n",
    "normalized_continuous = pd.DataFrame(normalized_continuous, columns=continuous_df.columns)\n",
    "\n",
    "#Encode the categorical variables\n",
    "\n",
    "cat_to_encode = categorical_df[['response', 'education', 'gender', 'state', 'marital_status', 'policy_type', 'policy', 'renew_offer_type', 'sales_channel', 'vehicle_class']]\n",
    "\n",
    "cat_encoded = pd.get_dummies(cat_to_encode, drop_first=True)\n",
    "\n",
    "# Leaving others as ordinal\n",
    "\n",
    "cat_ordinal = categorical_df[['coverage', 'employmentstatus', 'location_code','vehicle_size']]\n",
    "\n",
    "\n",
    "coverage_ordinal = {'Basic': 1, 'Extended': 2, 'Premium': 3}\n",
    "\n",
    "cat_ordinal['coverage'] = cat_ordinal['coverage'].map(coverage_ordinal)\n",
    "\n",
    "\n",
    "\n",
    "employmentstatus_ordinal = {'Employed': 1, 'Unemployed': 2, 'Medical Leave': 3, 'Disabled': 4, 'Retired': 5}\n",
    "\n",
    "cat_ordinal['employmentstatus'] = cat_ordinal['employmentstatus'].map(employmentstatus_ordinal)\n",
    "\n",
    "\n",
    "\n",
    "location_code_ordinal = {'Suburban': 1, 'Rural': 2, 'Urban': 3}\n",
    "\n",
    "cat_ordinal['location_code'] = cat_ordinal['location_code'].map(location_code_ordinal)\n",
    "\n",
    "\n",
    "\n",
    "vehicle_size_ordinal = {'Small': 1, 'Medsize': 2, 'Large': 3}\n",
    "\n",
    "cat_ordinal['vehicle_size'] = cat_ordinal['vehicle_size'].map(vehicle_size_ordinal)\n",
    "\n",
    "# converting to numeric\n",
    "\n",
    "cat_ordinal['coverage'] = pd.to_numeric(cat_ordinal['coverage'])\n",
    "cat_ordinal['employmentstatus'] = pd.to_numeric(cat_ordinal['employmentstatus'])\n",
    "cat_ordinal['location_code'] = pd.to_numeric(cat_ordinal['location_code'])\n",
    "cat_ordinal['vehicle_size'] = pd.to_numeric(cat_ordinal['vehicle_size'])\n",
    "\n",
    "# The time variable can be useful. \n",
    "#Try to transform its data into a useful one. Hint: Day week and month as integers might be useful.\n",
    "\n",
    "# effective_to_date already in date time\n",
    "\n",
    "# Since the model will only accept numerical data, check and make sure that every column is numerical, \n",
    "#if some are not, change it using encoding.\n",
    "\n",
    "# Will normalize discrete_df as well\n",
    "\n",
    "discrete_df['effective_to_date'] = pd.to_datetime(discrete_df['effective_to_date']).apply(lambda x: x.timestamp())\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "discrete_df['effective_to_date'] = scaler.fit_transform(discrete_df[['effective_to_date']])\n",
    "\n",
    "\n",
    "discrete_df = discrete_df.drop(['effective_to_date'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "normalized_discrete = scaler.fit_transform(discrete_df)\n",
    "normalized_discrete = pd.DataFrame(normalized_discrete, columns=discrete_df.columns)\n",
    "\n",
    "\n",
    "# Will concat all the data\n",
    "\n",
    "final_df = pd.concat([normalized_continuous, cat_ordinal, normalized_discrete, cat_encoded], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4458e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of code from previous labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a80fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. In this final lab, we will model our data. Import sklearn `train_test_split` and separate the data.\n",
    "\n",
    "model_df = pd.concat([continuous_df, cat_ordinal, discrete_df, cat_encoded], axis = 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = model_df.drop('total_claim_amount', axis = 1) \n",
    "y = model_df['total_claim_amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "786eecf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>total_claim_amount</td> <th>  R-squared:         </th>  <td>   0.626</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th>  <td>   0.624</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th>  <td>   361.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sun, 12 Nov 2023</td>  <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>13:42:42</td>      <th>  Log-Likelihood:    </th>  <td>  12523.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>  9134</td>       <th>  AIC:               </th> <td>-2.496e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>  9091</td>       <th>  BIC:               </th> <td>-2.465e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    42</td>       <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>nonrobust</td>     <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                          <td>    0.0572</td> <td>    0.007</td> <td>    7.957</td> <td> 0.000</td> <td>    0.043</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>customer_lifetime_value</th>        <td>-8.085e-08</td> <td> 1.03e-07</td> <td>   -0.786</td> <td> 0.432</td> <td>-2.82e-07</td> <td> 1.21e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>                         <td>-5.936e-07</td> <td> 2.76e-08</td> <td>  -21.491</td> <td> 0.000</td> <td>-6.48e-07</td> <td>-5.39e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coverage</th>                       <td>   -0.0047</td> <td>    0.002</td> <td>   -1.989</td> <td> 0.047</td> <td>   -0.009</td> <td>-6.79e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>employmentstatus</th>               <td>    0.0020</td> <td>    0.001</td> <td>    2.516</td> <td> 0.012</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>location_code</th>                  <td>   -0.0365</td> <td>    0.001</td> <td>  -38.112</td> <td> 0.000</td> <td>   -0.038</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vehicle_size</th>                   <td>   -0.0066</td> <td>    0.001</td> <td>   -5.428</td> <td> 0.000</td> <td>   -0.009</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_premium_auto</th>           <td>    0.0019</td> <td> 9.36e-05</td> <td>   20.004</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>months_since_last_claim</th>        <td>-2.047e-06</td> <td> 6.42e-05</td> <td>   -0.032</td> <td> 0.975</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>months_since_policy_inception</th>  <td> 6.028e-06</td> <td> 2.33e-05</td> <td>    0.258</td> <td> 0.796</td> <td>-3.97e-05</td> <td> 5.18e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_open_complaints</th>      <td>   -0.0004</td> <td>    0.001</td> <td>   -0.578</td> <td> 0.563</td> <td>   -0.002</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_of_policies</th>             <td>    0.0002</td> <td>    0.000</td> <td>    0.682</td> <td> 0.496</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>response_Yes</th>                   <td>   -0.0045</td> <td>    0.002</td> <td>   -2.259</td> <td> 0.024</td> <td>   -0.008</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_College</th>              <td>   -0.0023</td> <td>    0.002</td> <td>   -1.346</td> <td> 0.178</td> <td>   -0.006</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Doctor</th>               <td>   -0.0124</td> <td>    0.004</td> <td>   -3.484</td> <td> 0.000</td> <td>   -0.019</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_High School or Below</th> <td>    0.0082</td> <td>    0.002</td> <td>    4.841</td> <td> 0.000</td> <td>    0.005</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Master</th>               <td>   -0.0123</td> <td>    0.003</td> <td>   -4.795</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_M</th>                       <td>    0.0080</td> <td>    0.001</td> <td>    6.120</td> <td> 0.000</td> <td>    0.005</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state_California</th>               <td>    0.0010</td> <td>    0.002</td> <td>    0.533</td> <td> 0.594</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state_Nevada</th>                   <td>    0.0003</td> <td>    0.003</td> <td>    0.102</td> <td> 0.919</td> <td>   -0.005</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state_Oregon</th>                   <td>   -0.0012</td> <td>    0.002</td> <td>   -0.647</td> <td> 0.518</td> <td>   -0.005</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state_Washington</th>               <td>    0.0019</td> <td>    0.003</td> <td>    0.714</td> <td> 0.476</td> <td>   -0.003</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>marital_status_Married</th>         <td>   -0.0021</td> <td>    0.002</td> <td>   -1.091</td> <td> 0.275</td> <td>   -0.006</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>marital_status_Single</th>          <td>    0.0290</td> <td>    0.002</td> <td>   13.486</td> <td> 0.000</td> <td>    0.025</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_type_Personal Auto</th>      <td>    0.0016</td> <td>    0.003</td> <td>    0.617</td> <td> 0.537</td> <td>   -0.003</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_type_Special Auto</th>       <td>    0.0062</td> <td>    0.004</td> <td>    1.754</td> <td> 0.079</td> <td>   -0.001</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_Corporate L2</th>            <td>    0.0008</td> <td>    0.004</td> <td>    0.205</td> <td> 0.838</td> <td>   -0.007</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_Corporate L3</th>            <td>   -0.0005</td> <td>    0.004</td> <td>   -0.144</td> <td> 0.885</td> <td>   -0.008</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_Personal L1</th>             <td>    0.0024</td> <td>    0.002</td> <td>    1.475</td> <td> 0.140</td> <td>   -0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_Personal L2</th>             <td>   -0.0004</td> <td>    0.001</td> <td>   -0.271</td> <td> 0.787</td> <td>   -0.003</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_Personal L3</th>             <td>   -0.0004</td> <td>    0.001</td> <td>   -0.345</td> <td> 0.730</td> <td>   -0.003</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_Special L1</th>              <td>    0.0112</td> <td>    0.006</td> <td>    1.855</td> <td> 0.064</td> <td>   -0.001</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_Special L2</th>              <td>   -0.0011</td> <td>    0.004</td> <td>   -0.258</td> <td> 0.796</td> <td>   -0.010</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>policy_Special L3</th>              <td>   -0.0038</td> <td>    0.004</td> <td>   -0.846</td> <td> 0.398</td> <td>   -0.013</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renew_offer_type_Offer2</th>        <td>    0.0077</td> <td>    0.002</td> <td>    4.752</td> <td> 0.000</td> <td>    0.005</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renew_offer_type_Offer3</th>        <td>    0.0036</td> <td>    0.002</td> <td>    1.847</td> <td> 0.065</td> <td>   -0.000</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renew_offer_type_Offer4</th>        <td>    0.0005</td> <td>    0.002</td> <td>    0.207</td> <td> 0.836</td> <td>   -0.004</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sales_channel_Branch</th>           <td>    0.0001</td> <td>    0.002</td> <td>    0.076</td> <td> 0.940</td> <td>   -0.003</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sales_channel_Call Center</th>      <td>   -0.0005</td> <td>    0.002</td> <td>   -0.265</td> <td> 0.791</td> <td>   -0.004</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sales_channel_Web</th>              <td>    0.0005</td> <td>    0.002</td> <td>    0.245</td> <td> 0.806</td> <td>   -0.003</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vehicle_class_Luxury Car</th>       <td>    0.0063</td> <td>    0.013</td> <td>    0.474</td> <td> 0.635</td> <td>   -0.020</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vehicle_class_Luxury SUV</th>       <td>   -0.0070</td> <td>    0.013</td> <td>   -0.530</td> <td> 0.596</td> <td>   -0.033</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vehicle_class_SUV</th>              <td>   -0.0057</td> <td>    0.004</td> <td>   -1.286</td> <td> 0.199</td> <td>   -0.014</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vehicle_class_Sports Car</th>       <td>   -0.0151</td> <td>    0.005</td> <td>   -2.964</td> <td> 0.003</td> <td>   -0.025</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vehicle_class_Two-Door Car</th>     <td>    0.0005</td> <td>    0.002</td> <td>    0.285</td> <td> 0.776</td> <td>   -0.003</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1262.421</td> <th>  Durbin-Watson:     </th> <td>   1.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>9975.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.419</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 8.051</td>  <th>  Cond. No.          </th> <td>1.27e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.35e-19. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:     total_claim_amount   R-squared:                       0.626\n",
       "Model:                            OLS   Adj. R-squared:                  0.624\n",
       "Method:                 Least Squares   F-statistic:                     361.9\n",
       "Date:                Sun, 12 Nov 2023   Prob (F-statistic):               0.00\n",
       "Time:                        13:42:42   Log-Likelihood:                 12523.\n",
       "No. Observations:                9134   AIC:                        -2.496e+04\n",
       "Df Residuals:                    9091   BIC:                        -2.465e+04\n",
       "Df Model:                          42                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================================\n",
       "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------\n",
       "const                              0.0572      0.007      7.957      0.000       0.043       0.071\n",
       "customer_lifetime_value        -8.085e-08   1.03e-07     -0.786      0.432   -2.82e-07    1.21e-07\n",
       "income                         -5.936e-07   2.76e-08    -21.491      0.000   -6.48e-07   -5.39e-07\n",
       "coverage                          -0.0047      0.002     -1.989      0.047      -0.009   -6.79e-05\n",
       "employmentstatus                   0.0020      0.001      2.516      0.012       0.000       0.004\n",
       "location_code                     -0.0365      0.001    -38.112      0.000      -0.038      -0.035\n",
       "vehicle_size                      -0.0066      0.001     -5.428      0.000      -0.009      -0.004\n",
       "monthly_premium_auto               0.0019   9.36e-05     20.004      0.000       0.002       0.002\n",
       "months_since_last_claim        -2.047e-06   6.42e-05     -0.032      0.975      -0.000       0.000\n",
       "months_since_policy_inception   6.028e-06   2.33e-05      0.258      0.796   -3.97e-05    5.18e-05\n",
       "number_of_open_complaints         -0.0004      0.001     -0.578      0.563      -0.002       0.001\n",
       "number_of_policies                 0.0002      0.000      0.682      0.496      -0.000       0.001\n",
       "response_Yes                      -0.0045      0.002     -2.259      0.024      -0.008      -0.001\n",
       "education_College                 -0.0023      0.002     -1.346      0.178      -0.006       0.001\n",
       "education_Doctor                  -0.0124      0.004     -3.484      0.000      -0.019      -0.005\n",
       "education_High School or Below     0.0082      0.002      4.841      0.000       0.005       0.012\n",
       "education_Master                  -0.0123      0.003     -4.795      0.000      -0.017      -0.007\n",
       "gender_M                           0.0080      0.001      6.120      0.000       0.005       0.010\n",
       "state_California                   0.0010      0.002      0.533      0.594      -0.003       0.005\n",
       "state_Nevada                       0.0003      0.003      0.102      0.919      -0.005       0.005\n",
       "state_Oregon                      -0.0012      0.002     -0.647      0.518      -0.005       0.003\n",
       "state_Washington                   0.0019      0.003      0.714      0.476      -0.003       0.007\n",
       "marital_status_Married            -0.0021      0.002     -1.091      0.275      -0.006       0.002\n",
       "marital_status_Single              0.0290      0.002     13.486      0.000       0.025       0.033\n",
       "policy_type_Personal Auto          0.0016      0.003      0.617      0.537      -0.003       0.006\n",
       "policy_type_Special Auto           0.0062      0.004      1.754      0.079      -0.001       0.013\n",
       "policy_Corporate L2                0.0008      0.004      0.205      0.838      -0.007       0.009\n",
       "policy_Corporate L3               -0.0005      0.004     -0.144      0.885      -0.008       0.007\n",
       "policy_Personal L1                 0.0024      0.002      1.475      0.140      -0.001       0.006\n",
       "policy_Personal L2                -0.0004      0.001     -0.271      0.787      -0.003       0.002\n",
       "policy_Personal L3                -0.0004      0.001     -0.345      0.730      -0.003       0.002\n",
       "policy_Special L1                  0.0112      0.006      1.855      0.064      -0.001       0.023\n",
       "policy_Special L2                 -0.0011      0.004     -0.258      0.796      -0.010       0.007\n",
       "policy_Special L3                 -0.0038      0.004     -0.846      0.398      -0.013       0.005\n",
       "renew_offer_type_Offer2            0.0077      0.002      4.752      0.000       0.005       0.011\n",
       "renew_offer_type_Offer3            0.0036      0.002      1.847      0.065      -0.000       0.007\n",
       "renew_offer_type_Offer4            0.0005      0.002      0.207      0.836      -0.004       0.005\n",
       "sales_channel_Branch               0.0001      0.002      0.076      0.940      -0.003       0.003\n",
       "sales_channel_Call Center         -0.0005      0.002     -0.265      0.791      -0.004       0.003\n",
       "sales_channel_Web                  0.0005      0.002      0.245      0.806      -0.003       0.004\n",
       "vehicle_class_Luxury Car           0.0063      0.013      0.474      0.635      -0.020       0.032\n",
       "vehicle_class_Luxury SUV          -0.0070      0.013     -0.530      0.596      -0.033       0.019\n",
       "vehicle_class_SUV                 -0.0057      0.004     -1.286      0.199      -0.014       0.003\n",
       "vehicle_class_Sports Car          -0.0151      0.005     -2.964      0.003      -0.025      -0.005\n",
       "vehicle_class_Two-Door Car         0.0005      0.002      0.285      0.776      -0.003       0.004\n",
       "==============================================================================\n",
       "Omnibus:                     1262.421   Durbin-Watson:                   1.975\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9975.145\n",
       "Skew:                           0.419   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.051   Cond. No.                     1.27e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.35e-19. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Try a simple linear regression with all the data to see whether we are getting good results.\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y,X).fit()\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c23b2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6314366885272034"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, Y_train)\n",
    "lm.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b9600cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 value is =  0.6\n",
      "The intercept of the model is =  0.0600495268418009\n",
      "The coefficients of the model are =  [-2.50175776e-08 -6.04641762e-07 -5.17031526e-03  2.00604622e-03\n",
      " -3.62234889e-02 -5.42968942e-03  1.88014254e-03  6.20439551e-07\n",
      " -5.20221648e-06 -3.29649010e-04  1.83556225e-04 -5.02175513e-03\n",
      " -2.60980681e-03 -1.48844863e-02  7.60523058e-03 -1.25159937e-02\n",
      "  7.46117720e-03  7.88284772e-04  5.20288099e-04 -1.27995037e-03\n",
      "  6.11982978e-04 -2.22973706e-03  3.00577420e-02 -1.42659094e-03\n",
      "  3.90294461e-03 -2.40833539e-03 -5.06370979e-03  1.05392026e-03\n",
      " -1.42149961e-03 -1.05901160e-03  8.43972424e-03  1.39611928e-03\n",
      " -5.93289891e-03  8.31955891e-03  2.31358881e-03 -3.37687692e-04\n",
      " -5.91048594e-04 -1.98381015e-03  7.78273289e-04  1.21544676e-02\n",
      " -1.36537137e-02 -5.07516297e-03 -1.59914716e-02  2.61849941e-03]\n",
      "The mse of the model is =  0.0\n",
      "The root mse of the model is =  0.06\n",
      "The mean absolute error of the model is =  0.04\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, Y_train)\n",
    "lm.score(X_train, Y_train)\n",
    "\n",
    "predictions = lm.predict(X_test)\n",
    "\n",
    "print(\"R2 value is = \",round(r2_score(Y_test, predictions),2))\n",
    "print(\"The intercept of the model is = \",lm.intercept_)\n",
    "print(\"The coefficients of the model are = \",lm.coef_)\n",
    "\n",
    "mse = mean_squared_error(Y_test, predictions)\n",
    "mae = mean_absolute_error(Y_test, predictions)\n",
    "print(\"The mse of the model is = \", round(mse,2))\n",
    "print(\"The root mse of the model is = \",round(np.sqrt(mse),2))\n",
    "print(\"The mean absolute error of the model is = \",round(mae,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56eaff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Great! Now define a function that takes a list of models and train (and tests) them so we can try a lot of them without repeating code.\n",
    "\n",
    "def test_regression_model(X, Y):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "        'MLPRegressor': MLPRegressor()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        \n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(Y_test, predictions)\n",
    "        mse = mean_squared_error(Y_test, predictions)\n",
    "        mae = mean_absolute_error(Y_test, predictions)\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'R2': round(r2, 2),\n",
    "            'Root MSE': round(np.sqrt(mse),2),\n",
    "            'MAE': round(mae, 2)\n",
    "        }\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dba71400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "R2: 0.6\n",
      "Root MSE: 0.06\n",
      "MAE: 0.04\n",
      "\n",
      "Model: KNeighborsRegressor\n",
      "R2: 0.56\n",
      "Root MSE: 0.06\n",
      "MAE: 0.04\n",
      "\n",
      "Model: MLPRegressor\n",
      "R2: 0.66\n",
      "Root MSE: 0.06\n",
      "MAE: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = test_regression_model(X, Y)\n",
    "\n",
    "for model, metrics in results.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a902dc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e76b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ae981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7fb1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
